# ğŸ”„ Plan de MigraciÃ³n: Tiempo Real â†’ Batch Diario

## ğŸ“‹ Resumen del Cambio

**ACTUAL**: AnÃ¡lisis en tiempo real cada request  
**NUEVO**: AnÃ¡lisis batch 1x/dÃ­a + almacenamiento en DB

## ğŸ¯ Impacto del Cambio

### âœ… Ventajas
- **Menor latencia**: Frontend lee datos pre-calculados
- **Eficiencia de APIs**: Solo 1 anÃ¡lisis/dÃ­a por ticker
- **Consistencia**: Todos los usuarios ven los mismos datos
- **Historial**: Tracking de evoluciÃ³n de scores
- **Escalabilidad**: Mejor rendimiento con muchos usuarios

### âš ï¸ Desventajas  
- **Datos menos frescos**: MÃ¡ximo 24h de antigÃ¼edad
- **Complejidad**: Sistema mÃ¡s complejo con DB + scheduler
- **Recursos**: Necesita mÃ¡s infraestructura

## ğŸ› ï¸ Componentes a Modificar

### 1. **Nueva Dependencias** (pyproject.toml)
```toml
sqlalchemy = "^2.0.0"           # ORM
alembic = "^1.13.0"             # Migraciones DB
apscheduler = "^3.10.0"         # Scheduler
psycopg2-binary = "^2.9.0"      # PostgreSQL (opcional)
```

### 2. **Base de Datos** (nuevo)
```python
# database/
â”œâ”€â”€ models.py          # Modelos SQLAlchemy
â”œâ”€â”€ connection.py      # ConfiguraciÃ³n DB
â””â”€â”€ migrations/        # Migraciones Alembic
```

### 3. **Scheduler** (nuevo)
```python
# scheduler/
â”œâ”€â”€ job_scheduler.py   # APScheduler config
â”œâ”€â”€ daily_analysis.py  # Job principal
â””â”€â”€ job_monitoring.py  # Monitoreo de jobs
```

### 4. **Endpoints Modificados**
```python
# main.py - Cambios:
- /api/recommendations/daily â†’ /api/recommendations/latest
- /api/analysis/{ticker} â†’ /api/analysis/{ticker}/latest
+ /api/recommendations/history
+ /api/analysis/{ticker}/history
+ /api/jobs/status
```

### 5. **Servicios Adaptados**
```python
# services/ - Cambios mÃ­nimos:
- recommendation_engine.py: + save_to_db()
- Mantener lÃ³gica de anÃ¡lisis existente
- Agregar persistencia de resultados
```

## ğŸ“… Plan de ImplementaciÃ³n

### **Fase 1: PreparaciÃ³n (1-2 dÃ­as)**
1. Agregar dependencias de DB
2. Configurar SQLAlchemy + modelos
3. Crear migraciones iniciales
4. Setup de testing con DB

### **Fase 2: Batch System (2-3 dÃ­as)**
1. Crear job scheduler
2. Adaptar recommendation_engine para persistir datos
3. Implementar daily_analysis job
4. Sistema de monitoreo de jobs

### **Fase 3: API Migration (1 dÃ­a)**
1. Modificar endpoints para leer de DB
2. Mantener endpoints legacy como deprecated
3. Agregar endpoints de historial
4. Update documentaciÃ³n

### **Fase 4: Testing & Deploy (1 dÃ­a)**
1. Tests de integraciÃ³n
2. Migration scripts
3. Deployment con DB
4. Monitoreo y alertas

## ğŸ—„ï¸ Esquema de Base de Datos

### **Tabla: daily_recommendations**
```sql
CREATE TABLE daily_recommendations (
    id SERIAL PRIMARY KEY,
    analysis_date DATE NOT NULL,
    ticker VARCHAR(10) NOT NULL,
    recommendation VARCHAR(20) NOT NULL,  -- COMPRAR/MANTENER/VENDER
    total_score DECIMAL(5,2) NOT NULL,
    confidence DECIMAL(5,2) NOT NULL,
    technical_score DECIMAL(5,2),
    fundamental_score DECIMAL(5,2),
    macro_score DECIMAL(5,2),
    sentiment_score DECIMAL(5,2),
    current_price DECIMAL(10,2),
    target_price DECIMAL(10,2),
    risk_level VARCHAR(20),
    summary TEXT,
    created_at TIMESTAMP DEFAULT NOW(),
    UNIQUE(analysis_date, ticker)
);
```

### **Tabla: analysis_details**
```sql
CREATE TABLE analysis_details (
    id SERIAL PRIMARY KEY,
    recommendation_id INTEGER REFERENCES daily_recommendations(id),
    analysis_type VARCHAR(20) NOT NULL,  -- technical/fundamental/macro/sentiment
    raw_data JSONB,
    indicators JSONB,
    score DECIMAL(5,2),
    metadata JSONB,
    created_at TIMESTAMP DEFAULT NOW()
);
```

### **Tabla: job_runs**
```sql
CREATE TABLE job_runs (
    id SERIAL PRIMARY KEY,
    job_name VARCHAR(50) NOT NULL,
    start_time TIMESTAMP NOT NULL,
    end_time TIMESTAMP,
    status VARCHAR(20) NOT NULL,  -- running/completed/failed
    tickers_processed INTEGER,
    errors_count INTEGER,
    log_data JSONB,
    created_at TIMESTAMP DEFAULT NOW()
);
```

## âš™ï¸ ConfiguraciÃ³n de Scheduler

### **Cron Expression**
```python
# Ejecutar todos los dÃ­as a las 6:00 AM
DAILY_ANALYSIS_CRON = "0 6 * * *"

# Ejecutar dÃ­as laborales a las 6:00 AM (mÃ¡s conservador)
WEEKDAY_ANALYSIS_CRON = "0 6 * * 1-5"
```

### **Job Configuration**
```python
# config/scheduler.py
SCHEDULER_JOBS = [
    {
        'id': 'daily_analysis',
        'func': 'scheduler.daily_analysis:run_daily_analysis',
        'trigger': 'cron',
        'hour': 6,
        'minute': 0,
        'max_instances': 1,
        'coalesce': True
    }
]
```

## ğŸ”§ Variables de Entorno Nuevas

```env
# Base de datos
DATABASE_URL=sqlite:///./argenta_ia.db
# O PostgreSQL: postgresql://user:pass@localhost/argenta_ia

# Scheduler
SCHEDULER_ENABLED=true
DAILY_ANALYSIS_HOUR=6
DAILY_ANALYSIS_TIMEZONE=America/Argentina/Buenos_Aires

# Jobs
JOB_TIMEOUT_MINUTES=60
MAX_RETRIES=3
```

## ğŸ§ª Testing Strategy

### **Tests de Base de Datos**
```python
# tests/test_database.py
- Test de conexiÃ³n
- Test de modelos
- Test de queries
- Test de migraciones
```

### **Tests de Scheduler**
```python
# tests/test_scheduler.py  
- Test de job execution
- Test de error handling
- Test de concurrencia
- Test de monitoreo
```

### **Tests de MigraciÃ³n**
```python
# tests/test_migration.py
- Test de compatibilidad endpoints
- Test de performance DB vs tiempo real
- Test de datos histÃ³ricos
```

## ğŸ“Š MÃ©tricas y Monitoreo

### **MÃ©tricas Clave**
- Tiempo de ejecuciÃ³n de job diario
- Tickers procesados exitosamente
- Errores por tipo de anÃ¡lisis
- Latencia de endpoints
- Uso de recursos de DB

### **Alertas**
- Job fallido > 3 veces
- Tiempo de ejecuciÃ³n > 1 hora
- DB connection errors
- Espacio en disco bajo

## ğŸš€ Deployment Considerations

### **OpciÃ³n 1: SQLite (Simple)**
- Archivo local `argenta_ia.db`
- No requiere servidor DB externo
- Ideal para desarrollo/testing

### **OpciÃ³n 2: PostgreSQL (ProducciÃ³n)**
- Base de datos externa
- Mejor para concurrencia
- Backup y recovery robusto

### **Docker Compose**
```yaml
services:
  api:
    build: .
    depends_on: [db]
    environment:
      - DATABASE_URL=postgresql://user:pass@db/argenta_ia
  
  db:
    image: postgres:15
    environment:
      POSTGRES_DB: argenta_ia
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
```

## â“ Decisiones Pendientes

1. **Base de datos**: Â¿SQLite o PostgreSQL?
2. **Scheduler**: Â¿APScheduler o Celery?
3. **MigraciÃ³n**: Â¿Gradual o completa?
4. **Historial**: Â¿CuÃ¡ntos dÃ­as mantener?
5. **Fallback**: Â¿Mantener anÃ¡lisis en tiempo real como backup?

## ğŸ’¡ RecomendaciÃ³n

**Sugiero implementaciÃ³n gradual:**

1. **Fase MVP**: SQLite + APScheduler integrado
2. **Mantener endpoints actuales** como fallback
3. **Nuevos endpoints** para datos de DB
4. **Frontend puede elegir** tiempo real vs cached
5. **MigraciÃ³n completa** una vez validado

Â¿Te parece bien este approach? Â¿QuÃ© prefieres para la base de datos? 